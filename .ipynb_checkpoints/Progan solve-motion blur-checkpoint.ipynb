{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from train import *\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from math import log2\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as nnf\n",
    "torch.manual_seed(1)\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_blur(image,kernel_size = 3,sigma = 2):\n",
    "    channels = 3\n",
    "    motion_b_filter = np.zeros((kernel_size, kernel_size), np.float32)\n",
    "    motion_b_filter[int((kernel_size - 1)/2), :] = np.ones(kernel_size)  # horizontal blurr\n",
    "    #motion_b_filter[:, int((kernel_size - 1)/2)] = np.ones(kernel_size)  # vertical blurr\n",
    "    motion_b_filter /= kernel_size\n",
    "    motion_b_filter = torch.FloatTensor(motion_b_filter).unsqueeze(0).unsqueeze(0)\n",
    "    motion_b_filter = torch.repeat_interleave(motion_b_filter, channels, dim=0)\n",
    "    #print(gaussian_filter.shape)\n",
    "    weight = nn.Parameter(data=motion_b_filter, requires_grad=False).to(device)\n",
    "    image = nnf.conv2d(image, weight, padding=2, groups=channels).to(device)\n",
    "    return image\n",
    "\n",
    "def ProGAN_solver(test_img='Gabrielle Anwar',savedir='out_images_test'):\n",
    "    savedir = 'motion_blur'\n",
    "    test_img = 'Gabrielle_blurred_h'\n",
    "    \n",
    "    nIter = 10001\n",
    "\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    \n",
    "    workers = 2\n",
    "    ngpu = 1\n",
    "    batch_size = 1  # just to make 4 dim\n",
    "    iters = np.array(np.geomspace(10,10,nIter),dtype=int)\n",
    "    fname = '../ProGAN_g/motion_blur/{}.jpg'.format(test_img)\n",
    "    image = io.imread(fname)\n",
    "    #x_test = resize(image, (int(config.Z_DIM*2), int(config.Z_DIM*2)),anti_aliasing=True,preserve_range=True,mode='reflect')\n",
    "    image_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                          transforms.Resize(size=(int(config.Z_DIM*2), int(config.Z_DIM*2))),\n",
    "                                        transforms.ToTensor()])\n",
    "    test_images = image_transform(image)\n",
    "    test_images = test_images.unsqueeze(0)\n",
    "    print(test_images.shape)\n",
    "    print('type of test_images',type(test_images))\n",
    "    #x_test_ = np.array(test_images)/255.\n",
    "    x_test_ = np.transpose(test_images.detach().cpu().numpy(),[0,1,2,3])\n",
    "    x_test_ = x_test_/255.\n",
    "    print('type of x_test',type(x_test_))\n",
    "    #test_images = torch.Tensor(np.transpose(image[:batch_size,:,:,:],[0,3,1,2]))\n",
    "    Z_DIM = 256 #latent dimensionality of GAN (fixed)\n",
    "    IN_CHANNELS = 256\n",
    "    CHANNELS_IMG = 3\n",
    "    #io.imsave('{}/gt.png'.format(savedir),(image).astype(np.uint8))\n",
    "    save_image(test_images,'{}/gt.png'.format(savedir))\n",
    "    \n",
    "    genPATH = './ProGAN_g/generator.pth'\n",
    "    #gen = Generator(config.Z_DIM, config.IN_CHANNELS, img_channels=config.CHANNELS_IMG).to(config.DEVICE)\n",
    "    gen = Generator(Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG).to(device)\n",
    "    # LOAD THE WEIGHTS AT THIS STAGE\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.99))\n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        \n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        gen = nn.DataParallel(gen, list(range(ngpu)))\n",
    "        print('lol')\n",
    "    if os.path.isfile(genPATH):\n",
    "        if device.type == 'cuda':\n",
    "            gen.load_state_dict(torch.load(genPATH))\n",
    "        elif device.type=='cpu':\n",
    "            gen.load_state_dict(torch.load(genPATH,map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            raise Exception(\"Unable to load model to specified device\")\n",
    "\n",
    "        print(\"************ Generator weights restored! **************\")\n",
    "        gen.eval()\n",
    "    gen.eval()\n",
    "    #criterion = nn.MSELoss(reduction='sum')\n",
    "    criterion = nn.SmoothL1Loss(reduction='sum')\n",
    "    FIXED_NOISE = torch.randn(1, Z_DIM, 1, 1).to(DEVICE)\n",
    "    #z_prior = torch.zeros(165,Z_DIM,1,1,requires_grad=True,device=device)\n",
    "    optimizerZ = optim.RMSprop([FIXED_NOISE], lr=5e-3)\n",
    "\n",
    "    real_cpu = test_images.to(device)\n",
    "    \n",
    "    for iters in range(nIter):\n",
    "        optimizerZ.zero_grad()\n",
    "        opt_gen.zero_grad()\n",
    "        z2 = torch.clamp(FIXED_NOISE,-1.,1.)\n",
    "        #z2 = FIXED_NOISE\n",
    "        fake = 0.5*gen(z2, 1e-5,int(log2(config.START_TRAIN_AT_IMG_SIZE / 4)))+0.5\n",
    "        fake = motion_blur(fake, 5)\n",
    "        cost = 0\n",
    "        for i in range(3):\n",
    "            y_gt = real_cpu[:,i,:,:]\n",
    "            y_est = fake[:,i,:,:]\n",
    "            cost += criterion(y_gt,y_est)\n",
    "        \n",
    "        cost.backward()\n",
    "        optimizerZ.step()\n",
    "        opt_gen.step()\n",
    "        if (iters % 100 == 0):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                z2 = torch.clamp(FIXED_NOISE,-1.,1.)\n",
    "                fake = 0.5*gen(z2, 1e-5,int(log2(config.START_TRAIN_AT_IMG_SIZE / 4))).detach().cpu() + 0.5\n",
    "                G_imgs = np.transpose(fake.detach().cpu().numpy(),[0,1,2,3])\n",
    "                G_img_psnr = G_imgs\n",
    "                print(G_img_psnr.shape)\n",
    "                G_imgs = torch.Tensor(G_imgs)\n",
    "            \n",
    "            print('G_img type',type(G_img_psnr))\n",
    "            print('xtest type', type(x_test_))\n",
    "            psnr = compare_psnr(x_test_,G_img_psnr,data_range=1.0)\n",
    "            print('Iter: {:d}, Error: {:.3f}'.format(iters,cost.item()))\n",
    "            #io.imsave('{}/inv_solution_iters_{}.png'.format(savedir,str(iters).zfill(4)),(G_imgs).astype(np.uint8))\n",
    "            #save_image(G_imgs, f'out_images_test/inv_solution_iters_{iters}.png')\n",
    "            save_image(G_imgs,'{}/inv_solution_iters_{}.png'.format(savedir, iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "type of test_images <class 'torch.Tensor'>\n",
      "type of x_test <class 'numpy.ndarray'>\n",
      "=> Loading checkpoint\n",
      "(1, 3, 512, 512)\n",
      "G_img type <class 'numpy.ndarray'>\n",
      "xtest type <class 'numpy.ndarray'>\n",
      "Iter: 0, Error: 97514.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 415.07 MiB already allocated; 9.08 MiB free; 458.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a67c599b299d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mProGAN_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-369b5756e0d5>\u001b[0m in \u001b[0;36mProGAN_solver\u001b[1;34m(test_img, savedir)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_gt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_est\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0moptimizerZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 4.00 GiB total capacity; 415.07 MiB already allocated; 9.08 MiB free; 458.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ProGAN_solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
