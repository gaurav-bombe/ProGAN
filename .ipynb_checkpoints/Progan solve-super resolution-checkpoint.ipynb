{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from train import *\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from math import log2\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as nnf\n",
    "torch.manual_seed(2)\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(fname):\n",
    "    \n",
    "    downsample = nnf.interpolate(fname, size=None, scale_factor=0.25, mode='bicubic')  # use either of size or scale factor\n",
    "    \n",
    "    return downsample\n",
    "\n",
    "def ProGAN_solver(test_img='Gabrielle Anwar',savedir='out_images_test'):\n",
    "    savedir = 'downsample'\n",
    "    test_img = 'gabrielle_test_cubic'\n",
    "    \n",
    "    nIter = 10001\n",
    "\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    \n",
    "    workers = 2\n",
    "    ngpu = 1\n",
    "    batch_size = 1  # just to make 4 dim\n",
    "    iters = np.array(np.geomspace(10,10,nIter),dtype=int)\n",
    "    fname = '../ProGAN_g/downsample/{}.jpg'.format(test_img)\n",
    "    image = io.imread(fname)\n",
    "    #x_test = resize(image, (int(config.Z_DIM*2), int(config.Z_DIM*2)),anti_aliasing=True,preserve_range=True,mode='reflect')\n",
    "    image_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.ToTensor()])\n",
    "    test_images = image_transform(image)\n",
    "    test_images = test_images.unsqueeze(0)\n",
    "    x_test_ = np.array(test_images)/255.\n",
    "    print(test_images.shape)\n",
    "    #test_images = torch.Tensor(np.transpose(image[:batch_size,:,:,:],[0,3,1,2]))\n",
    "    Z_DIM = 256 #latent dimensionality of GAN (fixed)\n",
    "    IN_CHANNELS = 256\n",
    "    CHANNELS_IMG = 3\n",
    "    save_image(test_images,'{}/gt.png'.format(savedir))\n",
    "    #io.imsave('{}/gt.png'.format(savedir),(image).astype(np.uint8))\n",
    "    \n",
    "    genPATH = './ProGAN_g/generator.pth'\n",
    "    #gen = Generator(config.Z_DIM, config.IN_CHANNELS, img_channels=config.CHANNELS_IMG).to(config.DEVICE)\n",
    "    gen = Generator(Z_DIM, IN_CHANNELS, img_channels=CHANNELS_IMG).to(device)\n",
    "    # LOAD THE WEIGHTS AT THIS STAGE\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.0, 0.99))\n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        \n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        gen = nn.DataParallel(gen, list(range(ngpu)))\n",
    "        print('lol')\n",
    "    if os.path.isfile(genPATH):\n",
    "        if device.type == 'cuda':\n",
    "            gen.load_state_dict(torch.load(genPATH))\n",
    "        elif device.type=='cpu':\n",
    "            gen.load_state_dict(torch.load(genPATH,map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            raise Exception(\"Unable to load model to specified device\")\n",
    "\n",
    "        print(\"************ Generator weights restored! **************\")\n",
    "        gen.eval()\n",
    "    gen.eval()\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = nn.SmoothL1Loss(reduction='sum')\n",
    "    FIXED_NOISE = torch.randn(1, Z_DIM, 1, 1).to(DEVICE)\n",
    "    #z_prior = torch.zeros(165,Z_DIM,1,1,requires_grad=True,device=device)\n",
    "    optimizerZ = optim.RMSprop([FIXED_NOISE], lr=5e-3)\n",
    "\n",
    "    real_cpu = test_images.to(device)\n",
    "    \n",
    "    for iters in range(nIter):\n",
    "        optimizerZ.zero_grad()\n",
    "        opt_gen.zero_grad()\n",
    "        z2 = torch.clamp(FIXED_NOISE,-1.,1.)\n",
    "        #z2 = FIXED_NOISE\n",
    "        fake = 0.5*gen(z2, 1e-5,int(log2(config.START_TRAIN_AT_IMG_SIZE / 4)))+0.5\n",
    "        #print('gen shape:',fake.shape)\n",
    "        fake = downsampling(fake)\n",
    "        #print('downsam_gen shape:',fake.shape)\n",
    "        cost = 0\n",
    "        for i in range(3):\n",
    "            y_gt = real_cpu[:,i,:,:]\n",
    "            y_est = fake[:,i,:,:]\n",
    "            cost += criterion(y_gt,y_est)\n",
    "        \n",
    "        cost.backward()\n",
    "        optimizerZ.step()\n",
    "        opt_gen.step()\n",
    "        if (iters % 100 == 0):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                z2 = torch.clamp(FIXED_NOISE,-1.,1.)\n",
    "                fake = 0.5*gen(z2, 1e-5,int(log2(config.START_TRAIN_AT_IMG_SIZE / 4))).detach().cpu() + 0.5\n",
    "                G_imgs = np.transpose(fake.detach().cpu().numpy(),[0,1,2,3])\n",
    "                G_imgs = torch.Tensor(G_imgs)\n",
    "            \n",
    "            print('x test da shape hove',x_test_.shape)\n",
    "            print('G_imgs test da shape hove',G_imgs.shape)\n",
    "            psnr = compare_psnr(x_test_,G_imgs,data_range=1.0)\n",
    "            print('Iter: {:d}, Error: {:.3f}'.format(iters,cost.item()))\n",
    "            #io.imsave('{}/inv_solution_iters_{}.png'.format(savedir,str(iters).zfill(4)),(G_imgs).astype(np.uint8))\n",
    "            #save_image(G_imgs, f'out_images_test/inv_solution_iters_{iters}.png')\n",
    "            save_image(G_imgs,'{}/inv_solution_iters_{}.png'.format(savedir, iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 128, 128])\n",
      "=> Loading checkpoint\n",
      "x test da shape hove (1, 3, 128, 128)\n",
      "G_imgs test da shape hove torch.Size([1, 3, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input images must have the same dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a67c599b299d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mProGAN_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-fca106b33f47>\u001b[0m in \u001b[0;36mProGAN_solver\u001b[1;34m(test_img, savedir)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x test da shape hove'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'G_imgs test da shape hove'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_imgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mpsnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iter: {:d}, Error: {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;31m#io.imsave('{}/inv_solution_iters_{}.png'.format(savedir,str(iters).zfill(4)),(G_imgs).astype(np.uint8))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\measure\\simple_metrics.py\u001b[0m in \u001b[0;36mcompare_psnr\u001b[1;34m(im_true, im_test, data_range)\u001b[0m\n\u001b[0;32m     63\u001b[0m          \u001b[1;34m'skimage.metrics.peak_signal_noise_ratio. It will be removed from '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m          'skimage.measure in version 0.18.', stacklevel=2)\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeak_signal_noise_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\metrics\\simple_metrics.py\u001b[0m in \u001b[0;36mpeak_signal_noise_ratio\u001b[1;34m(image_true, image_test, data_range)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \"\"\"\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[0mcheck_shape_equality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_range\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py\u001b[0m in \u001b[0;36mcheck_shape_equality\u001b[1;34m(im1, im2)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;34m\"\"\"Raise an error if the shape do not match.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mim1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mim2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input images must have the same dimensions.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input images must have the same dimensions."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ProGAN_solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
